## Тестовое задание по классификации текстов

### Описание задачи

Необходимо разработать качественный классификатор текстов новостей.  

### Набор данных

Содержит 835 текстов новостей (поле ‘content’) и 16 классов (поле ‘classification’) этих новостей.  
Данные сильно несбалансированны.  

### Решение  

Задача представляет собой многоклассовую классификацию текстов.  
В качестве решений используется комбинация предсказаний TF-IDF и Logistic Regression и BERT.
Задание выполнено на языке Python.  
В качестве метрика используется f1-macro  

### Требование к оборудованию

Для более воспроизведения результатов приведенных в ноутбуке может потребоваться GPU.  
Также происходит дообучение BERT, что без GPU займет очень много времени, но в папке models есть педобученная модель.  
Используйте ее.  
Других специфичных требований к ПК нет.  

### Используемые библиотеки

Cписок библиотек и фреймворков, которые используются в проекте:

- PyTorch
- Scikit-learn
- NLTK
- CatBoost
- transformers
- scipy
- pandas
- numpy
- nlpaug

## Требования к подготовке среды

1. **Python 3.x**: Убедитесь, что на вашем компьютере установлена версия Python 3.x. [Официальный сайт Python](https://www.python.org/)

2. **Виртуальное окружение (рекомендуется)**: Рекомендуется создать виртуальное окружение для изоляции зависимостей.

   python -m venv venv
   source venv/bin/activate  # Для Linux / macOS  
   .\venv\Scripts\activate   # Для Windows  

   pip install -r requirements.txt  

   Для установки зависимостей в jupyter notebook используйте  
   ! pip install -r requirements.txt  

### Структура 

├── data  
│   ├── GBC_NLP_test_news_sample.json  
├── models  
    ├── bert_trained.pt  
├── GlowByte_NLP.ipynb  
├── src  
│   ├── functions_LR.py  
│   ├── functions_bert.py  
├── README.md  
├── requirements.txt  
